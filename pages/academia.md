---
layout: page
title: Academia
permalink: /academia/
---

## On the Significance of Academia

Academic institutions as an ideal aim to pursue and produce knowledge across a wide variety of subjects. Across both the hard sciences as well as the humanities, they have been unparalleled in their influence on thought within societies today on a technological as well as a cultural level. Such institutions, regardless of one's thoughts on how well they achieve their aims, have nonetheless done a lot of good for the society, and such institutions are invaluable. This is for the following reasons:

- Knowledge is crucial for the advancement of society in terms of its quality of life, and a lot of research that has such effects is unlikely to be immediately profitable. Because of this lack of profitability, private firms cannot be expected to engage in the perfectly optimal level of innovation that would increase societal well-being. For this, governments as well as academic institutions have to take up the responsibility, after which firms can reap the benefits of the knowledge which would not have been produced otherwise (see [Maximizing Innovation and Technology](https://prometheandissident.github.io/economics/#maximizing-innovation-and-technology)).
- Due to transaction costs, it is difficult for individual researchers to collaborate with one another on large-scale research projects which involve more than one individual's resources and/or expertise. Academic institutions provide an easier means by which researchers can communicate with one another, either through informal networks that are created or physical proximity if the researchers are a part of the same institution. The latter is essential for the production of knowledge, as evidence suggests that researchers who are part of in-person teams are more likely to make scientific breakthroughs than researchers who are collaborating remotely<ref>https://www.nature.com/articles/d41586-023-03618-x</ref>.
- Scientific collaborations are characterized by hot spots and hot moments which are short but intense periods of collaboration which drive scientific and intellectual social movements. Emotions and bonding are essential for the group's growth and development, but increased size and diversity have the potential to erode the affective culture that generated initial successes<ref>https://journals.sagepub.com/doi/abs/10.1177/0003122411433763</ref>. Academic institutions help to drive this process.
- Academic institutions also serve the role of educating the workforce of tomorrow. While many including myself would argue that there is a problem with overcredentialization that has been created through an excess number of individuals attending university, some level of education is crucial for a number of jobs. A person shouldn't be able to become a doctor without basic medical training, for instance, and universities provide such educational opportunities.

Research shows that the dual functions of universities, to increase innovation as well as to educate the future workforce, lead to such institutions having positive effects on economic growth. Increases in the number of universities are positively associated with future GDP per capita, a relationship that is robust to a host of observables and unobserved regional trends. More specifically, doubling the number of universities per capita is associated with 4% higher future GDP per capita. Furthermore, there are positive spillover effects from universities to grographically close regions due to an increased supply of human capital and higher innovation<ref>https://www.nber.org/papers/w22501#:~:text=We%20develop%20a%20new%20dataset,spillover%20effects%20from%20universities%20to</ref>. Furthermore, in the United States, research has shown that some investments in university education have substantial positive growth effects<ref>https://web.archive.org/web/20160705042552/https://www.brookings.edu/economics/bpea/~/media/Files/Programs/ES/BPEA/2009_spring_bpea_papers/2009_spring_bpea_aghion_etal.pdf</ref>.

University degrees, the primary credential that individuals receive following post-secondary education, are not completely zero sum. A percentage point increase in the supply of college graduates raises high school dropouts wages by 1.9%, high school graduates' wages by 1.6%, and college graduates wages by 0.4%. This suggests spillovers and supply-demand pressures exist in labor markets<ref>https://eml.berkeley.edu/~moretti/socret.pdf#:~:text=college,supply%20of%20college%20graduates%20increases</ref>.

## How Academia Stacks up

But just because there are positives to academia doesn't mean that such institutions have not also done bad things or operated in optimal ways. I aim to show both the benefits of academic institutions as they exist today, as well as their limitations. In doing so, I will draw upon research looking at the validity of expert judgment, the validity of peer review, broader problems with academic research, as well as biases that academic institutions can exhibit. While discussing these limitations where they exist, it is important to always remember that academia is crucial for the functioning of society, and that some institution needs to take the role that current academic institutions do. So while some may advocate for reform of the current system in addressing its issues, or even the creation of alternative institutions (which is my view), completely getting rid of any possible system which fulfills the functions of academia would be extremely imprudent.

### The Validity of Experts

Much of academic discourse implicitly or explicitly premises itself on the notion that experts constitute some elite class of individuals who simply know so much more than the average person. There is some truth to this notion. In general, an expert will have more knowledge about the subject they have studied relative to the average person. Therefore, it is perfectly reasonable to take the fact that an expert on subject X makes proposition Y on that subject as evidence that proposition Y is true or likely to be true. However, many fail to recognize the limitations of expertise, and how the actual difference between experts and laymen is not as large as might be initially assumed. Thus, many autodidacts can likely outperform experts in their own field, at least on particular tasks which the autodidact has specialized within.

Expertise, defined by having some graduate or professional degree, is associated with an above-average level of intelligence, although the difference is relatively small. Research suggests that the average IQ of an individual with a graduate or professional degree is only 108, which is just over half a standard deviation above the population IQ mean in any industrialized country. Not terrible, but not super impressive either<ref>https://www.researchgate.net/figure/Distribution-of-IQs-as-a-function-of-highest-degree-completed-in-MTFS-sample-N2593_fig1_353203996</ref>:

<img src="https://www.researchgate.net/profile/Emily-Willoughby/publication/353203996/figure/fig1/AS:1060372534554624@1629823921068/Distribution-of-IQs-as-a-function-of-highest-degree-completed-in-MTFS-sample-N2593.png" alt="Distribution of IQs as a function of highest degree completed in MTFS sample" width="500">

With this small intelligence advantage that experts tend to have, experts in a particular field tend to lack the cognitive ability to make significant strides in their respective fields. While many believe that discoveries in science are made by a wide variety of individuals in any particular field, in reality they are made by a small minority. For example, it is only a relatively small number of physicists who contribute substantially to the advance of science through their research. Only about 15-20% of the work cited in significant discoveries is produced by average scientists. Even papers of minor significance tend to disproportionately use the work of eminent scientists. Most articles published even in leading journals receive very few citations. Independent multiple discoveries are extremely common within science, so the work of average scientists can easily be replaced. Major contributions to teaching are also likely done by a small handful of scientists, as the great majority of elite scientists are trained by other members of the elite<ref>https://www.science.org/doi/10.1126/science.178.4059.368</ref>.

Despite experts being trained to learn statistical techniques to a substantial degree, experts across a wide variety of fields lack data analysis skills and the ability to accurately interpret statistical information, including in fields such as medicine, epidemiology, cognitive science, psychology, business, and economics<ref>https://www.researchgate.net/publication/283175190_Blinding_Us_to_the_Obvious_The_Effect_of_Statistical_Training_on_the_Evaluation_of_Evidence</ref><ref>https://pubmed.ncbi.nlm.nih.gov/24420726/</ref><ref>https://www.researchgate.net/publication/235363101_Contemporary_Issues_in_the_Analysis_of_Data_A_Survey_of_551_Psychologists</ref><ref>https://www.researchgate.net/publication/27262211_Misinterpretations_of_Significance_A_Problem_Students_Share_with_Their_Teachers</ref><ref>https://www.cambridge.org/core/services/aop-cambridge-core/content/view/D1520CFBFEB2C282E93484057D84B6C6/S183449091900028Xa.pdf/beyond_psychology_prevalence_of_p_value_and_confidence_interval_misinterpretation_across_different_fields.pdf</ref>. This problem even extends to statisticians, the very individuals whose expertise is premised upon knowledge of statistics<ref>https://onlinelibrary.wiley.com/doi/abs/10.1080/00207590244000250</ref>! Part of the issue is with how statistical evidence is taught in universities. The concept of "statistical significance", while valuable to determine the validity of certain results, is overwhelmingly used as a threshold market to dichotomize "valid" versus "invalid" evidence as opposed to what it is in reality<ref>https://amstat.tandfonline.com/doi/abs/10.1080/01621459.2017.1289846#.YeL28GjMKUk</ref>, which is a continuum. A p-value of 0.051 is not much different from a p-value of 0.049 in practical terms, but only one is "statistically significant" while one isn't. While this confusion that many experts have about statistical interpretation cannot be blamed on the experts themselves, it along with the broader lack of statistical knowledge is indicative of experts not knowing as much as many think they do.

Furthermore, experts oftentimes struggle to make judgments when compared with statistical modeling. A meta-analysis comparing statistical and clinical predictions found that statistical predictions outperformed clinical ones by about 13 percent. This improvement in predictions occurs in things including brain impairment, academic performance, psychiatric diagnoses, psychotherapy outcomes, length of psychotherapy, prognoses, matching MMPI profiles to persons, compliance with counseling plans, lengths of hospital stay, criminal offending, IQ, suicide attempts, training performance, personality characteristics, adjustment, martial success, career satisfaction, prior hospitalization, homicidality, lying and juvenile delinquency, among others<ref>https://journals.sagepub.com/doi/10.1177/0011000005285875</ref>. More information, while improving the statistical models’ judgment ability, reduced the clinicians judgment ability.

Similar results have been found in criminological evaluations. The predictions of people who make parole decisions as for future risk and rehabilitation of criminals, despite being based on diagnostic judgments identifying causes of crime such as personal dispositions, drugs, alcohol, money and environment, were virtually unrelated to known post-release outcomes of criminals. An actuarial prediction device however is able to predict risk and rehabilitation outcomes at a higher rate<ref>https://www.jstor.org/stable/3053536?seq=1</ref>.

In looking at forecasts, the story is slightly more positive towards experts, but less than would be expected. There, statistical models tend to perform better than humans, but perform worse than the best humans. Humans have an edge in generality especially in cases where there is no data, while statistical models do extremely well in predicting continuous trends as opposed to chaotic systems, when fed piles of data, and when modeling a stable quantity as opposed to something “anti-inductive” things like a financial market or someone reacting to predictions about it<ref>https://ifp.org/can-policymakers-trust-forecasters/</ref>.

Even in terms of interviews, which while not directly related to experts in the educational sense, still concern a broader domain-specific expertise in a particular industry or field, experts can perform poorly. Recruiters are only slightly better than a coin flip at making value judgments regarding resumes, and they still disagree with each other about what a good candidate looks like. AI is better at judging resumes, making more accurate predictions than human recruiters even with very limited types of data inputted into the model<ref>https://web.archive.org/web/20250403195747/https://interviewing.io/blog/are-recruiters-better-than-a-coin-flip-at-judging-resumes</ref>.

Furthermore, unstructured interviews that individuals are presented with when making hiring decisions along with test scores create overconfidence relative to just those who know an applicant’s test scores. This overconfidence leads to fewer payoffs in an experiment and suggests that these interviews can actually hurt personnel selection decisions<ref>https://www.sciencedirect.com/science/article/abs/pii/S0749597816304629</ref>. The problem with overconfidence in interviewing is so significant that it even persists when individuals are answering questions randomly. People using screening interviews form just as confident an impression from people answering questions using a random response system as from people actually answering the questions, which can interfere with the use of valid information<ref>https://www.cambridge.org/core/journals/judgment-and-decision-making/article/belief-in-the-unstructured-interview-the-persistence-of-an-illusion/5BBA77932EF22EBEAA1E8020126A1925</ref>.

Interviewing similarly fails to work in college admissions. In selection and admission decisions, a meta-analysis found that there was consistent and substantial loss of prediction validity when data were combined holistically even among experts across multiple criteria in work and academic settings. This took the form of prediction validity in predicting multiple work (advancement, supervisory ratings of performance, and training performance) and academic (grade point average) criteria. Mechanical prediction improves prediction validity by more than 50% compared to using people<ref>https://psycnet.apa.org/doiLanding?doi=10.1037%2Fa0034156</ref>. Research has similarly found that the interview process for medical school acceptance does not enhance the ability to predict performance of medical school applicants<ref>https://jamanetwork.com/journals/jama/article-abstract/363832</ref>.

With the rise of other technologies such as artificial intelligence, human experts will fall even further behind other methods when it comes to predicting certain phenomena. For example, research is already showing that large language models are surpassing human experts in terms of predicting neuroscience experimental outcomes<ref>https://arxiv.org/abs/2403.03230</ref>.

It is important to put all of this research into perspective. Yes, expertise is valuable in many contexts when one is unable to find other pieces of evidence for a particular claim. Furthermore, expertise is valuable in situations where one doesn't have the time or the ability to assess the claim themselves, however it may be assessed. We can't all do randomized controlled trials on the effects of a particular medication, and so at some point we have to put our trust in authorities who claim the effect is what they say it is. This should not be viewed as a suggestion to not trust expertise, but to understand that it has both strengths and limitations.

### The Validity of Peer Review

Peer review is oftentimes held up as the gold standard of validity in academic research. If something is peer reviewed, that means it must be true, and the process of peer review is crucial to upholding proper and true scientific inquiry. While peer review can be good in some contexts, as it can certainly help screen out obviously bad papers, its actual effectiveness is much less than one may initially believe.

Some problems pop out of the gate when it comes to non-blinded peer review (ie the author knows whose paper they're reviewing). This opens up doors to nepotism and other biases which may not have presented themselves otherwise. One consistent finding in the literatute on the effectiveness of peer review is that the prominence of an author affects the probability of the paper passing the review, independently of the content of the paper. Higher prominence means that the paper is more likely to get accepted for peer review<ref>Sci-Hub | Effect of Blinded Peer Review on Abstract Acceptance. JAMA, 295(14), 1675 | 10.1001/JAMA.295.14.1675. (n.d.). https://sci-hub.ru/https://doi.org/10.1001/jama.295.14.1675</ref><ref>Sci-Hub | Reviewer bias in single- versus double-blind peer review. Proceedings of the National Academy of Sciences, 114(48), 12708–12713 | 10.1073/pnas.1707323114. (n.d.). https://sci-hub.ru/https://doi.org/10.1073/pnas.1707323114</ref><ref>Huber, J., Inoua, S., Kerschbamer, R., König-Kersting, C., Palan, S., Smith, V. L., & University of Graz, School of Business, Economics and Social Sciences. (2022). Nobel and novice: Author prominence affects peer review. In University of Graz, School of Business, Economics and Social Sciences Working Paper (No. 2022–01). https://files.catbox.moe/z0pp2y.pdf</ref>. This is particularly true in the case of extremely high prominence, where for an identical paper, peer reviewers are more likely to accept it if the name it is attributed to is a Nobel laureate compared to an early career research associate<ref>https://www.pnas.org/doi/epub/10.1073/pnas.2205779119</ref>. Single-blind peer reviewers are significantly more likely than double-blind counterparts to recommend for acceptance papers from famous authors, top universities, and top companies<ref>Tomkins, A., Zhang, M., & Heavlin, W. D. (2017). Reviewer bias in single- versus double-blind peer review. Proceedings of the National Academy of Sciences, 114(48), 12708–12713. https://doi.org/10.1073/pnas.1707323114</ref>. While manuscripts appear to be improved by blinded peer reviewing<ref>Fletcher, R. H., & Fletcher, S. W. (1997). Evidence for the effectiveness of peer review. Science and Engineering Ethics, 3(1), 35–50. https://doi.org/10.1007/s11948-997-0015-5</ref>, research suggests that at least in social work few referees from prestigious or nonprestigious journals prepare reviews that are knowledgably, scientifically astute, or objective<ref>Sci-Hub | What errors do peer reviewers detect, and does training improve their ability to detect them? Journal of the Royal Society of Medicine, 101(10), 507–514 | 10.1258/jrsm.2008.080062. (n.d.). https://sci-hub.ru/https://doi.org/10.1258/jrsm.2008.080062</ref><ref>Sci-Hub | Confirmational Response Bias among Social Work Journals. Science, Technology, & Human Values, 15(1), 9–38 | 10.1177/016224399001500102. (n.d.). https://sci-hub.ru/https://doi.org/10.1177/016224399001500102</ref>.

Even when peer review is completely blinded, a number of problems with peer review persist. I will list several of them below:

- **Peer review is unreliable across reviewers -** There tends to be low interrater reliability amongst peer reviewers<ref>Mahoney, M. J. (1977). Publication prejudices: An experimental study of confirmatory bias in the peer review system. Cognitive Therapy and Research, 1(2), 161–175. https://doi.org/10.1007/bf01173636</ref><ref>Sci-Hub | Reproducibility of peer review in clinical neuroscience: Is agreement between reviewers any greater than would be expected by chance alone? Brain, 123(9), 1964–1969 | 10.1093/brain/123.9.1964. (n.d.). https://sci-hub.ru/https://doi.org/10.1093/brain/123.9.1964</ref><ref>Bornmann, L., Mutz, R., & Daniel, H. (2010). A Reliability-Generalization Study of Journal Peer Reviews: A Multilevel Meta-Analysis of Inter-Rater Reliability and its Determinants. PLoS ONE, 5(12), e14331. https://doi.org/10.1371/journal.pone.0014331</ref>.
- **Peer reviewers are biased against those they disagree with -** Peer reviewers tend to be biased against manuscripts which report results contrary to their theoretical perspective or political orientation, independent of the quality of the paper<ref>Abramowitz, S. I., Gomes, B., & Abramowitz, C. V. (1975). Publish or politic: Referee Bias in Manuscript review1. Journal of Applied Social Psychology, 5(3), 187–200. https://doi.org/10.1111/j.1559-1816.1975.tb00675.x</ref><ref>Mahoney, M. J. (1977). Publication prejudices: An experimental study of confirmatory bias in the peer review system. Cognitive Therapy and Research, 1(2), 161–175. https://doi.org/10.1007/bf01173636</ref>.
- **Bad papers can get past peer review -** In a particularly egregious example of this, to test the effectiveness of peer review process in selecting for high-quality papers, John Bohannon submitted 304 versions of a fatally flawed paper to open-access journals. More than half of the journals accepted the paper<ref>Bohannon, J. (2013). Who’s afraid of peer review? Science, 342(6154), 60–65. https://doi.org/10.1126/science.2013.342.6154.342_60</ref>.
- **Peer review biases for positive study results -** There tends to exist a bias in favor of studies which are statistically significant, often with positive results, and against studies which fail to reject a null hypothesis<ref>Sci-Hub | Consequences of prejudice against the null hypothesis. Psychological Bulletin, 82(1), 1–20 | 10.1037/h0076157. (n.d.). https://sci-hub.ru/https://doi.org/10.1037/h0076157</ref><ref>Statistical significance, reviewer evaluations, and the scientific process: Is there a (statistically) significant relationship? (n.d.). ResearchGate. https://www.researchgate.net/publication/232425228_Statistical_significance_reviewer_evaluations_and_the_scientific_process_Is_there_a_statistically_significant_relationship</ref><ref>Easterbrook, P., Gopalan, R., Berlin, J., & Matthews. (1991). Publication bias in clinical research. The Lancet, 337(8746), 867–872. https://doi.org/10.1016/0140-6736(91)90201-y</ref><ref>Sci-Hub | Publication Decisions Revisited: The effect of the outcome of statistical tests on the decision to publish and vice versa. The American Statistician, 49(1), 108 | 10.2307/2684823. (n.d.). https://sci-hub.ru/https://doi.org/10.2307/2684823</ref><ref>Sci-Hub | Testing for the presence of Positive-Outcome Bias in Peer Review. Archives of Internal Medicine, 170(21) | 10.1001/ArchInternmed.2010.406. (n.d.). https://sci-hub.ru/https://doi.org/10.1001/archinternmed.2010.406</ref><ref>Chopra, F., Haaland, I., Roth, C., & Stegmann, A. (2023). The null result penalty. The Economic Journal, 134(657), 193–219. https://doi.org/10.1093/ej/uead060</ref>. Statistically significantly outcomes have a higher probability of being fully reported compared to non-significant outcomes<ref>Dwan, K., Altman, D. G., Arnaiz, J. A., Bloom, J., Chan, A., Cronin, E., Decullier, E., Easterbrook, P. J., Von Elm, E., Gamble, C., Ghersi, D., Ioannidis, J. P. A., Simes, J., & Williamson, P. R. (2008). Systematic review of the empirical evidence of study publication bias and outcome reporting bias. PLoS ONE, 3(8), e3081. https://doi.org/10.1371/journal.pone.0003081</ref>. Positive results tend to increase down the hierarchy of the sciences<ref>Sci-Hub | “Positive” Results Increase Down the Hierarchy of the Sciences. PLoS ONE, 5(4), e10068 | 10.1371/journal.pone.0010068. (n.d.). https://sci-hub.ru/https://doi.org/10.1371/journal.pone.0010068</ref>. Positive results are becoming increasingly more common in published papers over time<ref>Fanelli, D. (2011). Negative results are disappearing from most disciplines and countries. Scientometrics, 90(3), 891–904. https://doi.org/10.1007/s11192-011-0494-7</ref>, and positive results tend to receive significantly more citations than null or negative results, at least amongst applied disciplines and the biological sciences<ref>Fanelli, D. (2012). Positive results receive more citations, but only in some disciplines. Scientometrics, 94(2), 701–709. https://doi.org/10.1007/s11192-012-0757-y</ref>. Positive results create publication bias in meta-analyses<ref>Song, F., Parekh-Bhurke, S., Hooper, L., Loke, Y. K., Ryder, J. J., Sutton, A. J., Hing, C. B., & Harvey, I. (2009). Extent of publication bias in different categories of research cohorts: a meta-analysis of empirical studies. BMC Medical Research Methodology, 9(1). https://doi.org/10.1186/1471-2288-9-79</ref><ref>Kicinski, M. (2013). Publication Bias in recent Meta-Analyses. PLoS ONE, 8(11), e81823. https://doi.org/10.1371/journal.pone.0081823</ref><ref>Kicinski, M., Springate, D. A., & Kontopantelis, E. (2015). Publication bias in meta‐analyses from the Cochrane Database of Systematic Reviews. Statistics in Medicine, 34(20), 2781–2793. https://doi.org/10.1002/sim.6525</ref>.

Strikingly, while many of these issues are well-known and have been studied extensively, there is little empirical research actually examining papers or maniscripts that have been accepted in peer reviewed journals versus those that haven't. One paper did examine road safety evaluation studies and assessed their validity on seven criteria: sampling technique, total sample size, mean sample size for each result, specification of accident or injury severity, study design, number of confounding factors controlled and number of moderator variables specified. In this literature, there were very few statistically reliable differences in study validity between studies published in peer reviewed journals and studies not published in such journals<ref>Sci-Hub | Are road safety evaluation studies published in peer reviewed journals more valid than similar studies not published in peer reviewed journals? Accident Analysis & Prevention, 30(1), 101–118 | 10.1016/s0001-4575(97)00068-7. (n.d.). https://sci-hub.ru/https://doi.org/10.1016/S0001-4575(97)00068-7</ref>. This isn't very good evidence to go off of, as the literature and broader context that road safety evaluation studies are conducted within are going to be much different than those where, for example, sociological studies are conducted in. But it does suggest that peer review's effects on the quality of papers may be small.

Beyond blinding peer reviewers to the identity of authors, other suggested reforms to address the issues of peer review are to both open up peer review and train peer reviewers<ref>Smith, R. (2006). Peer review: a flawed process at the heart of science and journals. Journal of the Royal Society of Medicine, 99(4), 178–182. https://doi.org/10.1258/jrsm.99.4.178</ref>. Open peer review would increase the degree of accountability that peer reviewers have, and thus incentivize them against particular biases which may have existed otherwise. Training peer reviewers to guard themselves against certain biases may also address some of the aforementioned issues.

In the current context, it is clear that peer review is far from perfect. This doesn't mean that we shouldn't use it, but it does mean that just because a particular work isn't peer reviewed it doesn't mean that it is invalid. Peer reviews are not some magical stamp which implies that some research is more valid by virtue of it being peer reviewed. Rather, it is a rough signal of quality at best.

### The Validity of the Impact Factor

One way that some might respond to the problems of peer review is to look for other measures which would indicate the quality of a journal. Peer review may be flawed, but certainly some peer reviewers are better than others. Shouldn't we look for better journals which have higher quality peer reviewers to ascertain the validity of research? The primary measure employed in this process is known as the "impact factor" of a journal. It measures the yearly mean number of article citations that have been published in the last two years. A higher impact factor for a journal is generally seen as an indication that a journal is more prestigious or important within a given field. Indeed, journal quality ratings by experts correlate with the impact factors of the journals. For example, research suggests that physicians ratings of a journal's quality are positively correlated with their impact factor<ref>Saha, S., Saint, S., & Christakis, D. A. (2003). Impact factor: a valid measure of journal quality? In J Med Libr Assoc (Vol. 91, Issue 1). https://www.ncbi.nlm.nih.gov/pmc/articles/PMC141186/pdf/i0025-7338-091-01-0042.pdf</ref>. There is a statistically significant relationship between effect strength and journal quality measured by impact factor<ref>Murtaugh, P. A. (2002). JOURNAL QUALITY, EFFECT SIZE, AND PUBLICATION BIAS IN META-ANALYSIS. The Ecological Society of America. https://doi.org/10.1890/0012-9658(2002)083</ref>.

Despite this belief in the validity of journals with a higher impact factor, evidence actually suggests that a higher impact factor or journal ranking may actually if anything predict a lower quality of research. Firstly, it should be noted that identical papers published in journals with a higher impact factor receive twice as many citations<ref>https://arxiv.org/abs/0908.3177</ref>. Researchers can effectively game prestige through publishing in journals which are more well-recognized in their field, irrespective of the actual quality of their work. This alone puts into question whether a higher impact factor for a journal is a product of the actual quality of papers, or simply a belief that exists irrespective of paper quality and becomes a self-referential folk belief in the process.

However, the most damning piece of evidence on this question is a study which found that the replicability and research quality of a paper in a journal decreases as the journal ranking increases as measured by the impact factor<ref>https://www.frontiersin.org/articles/10.3389/fnhum.2018.00037/full</ref>. In other words, a higher impact factor for a journal actually predicts worse quality of papers, contrary to the assumptions of researchers in general. In short, expert measures of the quality of academic research in journals is poor and may if anything may produce exact opposite ordinal rankings than exist when assessing the actual quality of papers.

## ================================================================ TO ADD BELOW ================================================================






## <span style="background-color:lightcoral">Schooling</span>

### <span style="background-color:orange">Returns to Education</span>

**Degrees are Mostly Signalling:** According to Abel & Deitz (2019), the average annual rate of return for a college bachelor's degree, in spite of rising college costs, is around 14%, meaning it is still a good investment<ref>https://libertystreeteconomics.newyorkfed.org/2019/06/despite-rising-costs-college-is-still-a-good-investment/</ref>. Research suggests that there is large variation depending on a number of factors. While college selectivity and where one studies has relatively little effect on a person's long-term financial returns to their education<ref>https://sci-hub.se/https://doi.org/10.1007/BF00992285</ref><ref>https://sci-hub.se/https://doi.org/10.1162/003355302320935089</ref>, what a person studies has a large effect on their financial returns<ref>https://www.economist.com/united-states/2015/03/12/it-depends-what-you-study-not-where</ref>. There exists substantial sheepskin effects on returns to education, where there are increases in earnings due to the credential itself as opposed to the underlying skills or abilities demonstrated by individuals<ref>http://econ.queensu.ca/pub/jdi/deutsch/edu_conf/Ferrer.pdf</ref><ref>https://www.econstor.eu/bitstream/10419/188353/1/pjcss433.pdf</ref>. In 2011, a Russian educational reform shortened the university study period by one year and reduced the content of the curricula but did not change the quality of admitted students. This had no adverse effect on wages and on the probability of being employed, suggesting no returns to higher education<ref>https://wp.hse.ru/data/2020/09/22/1584505319/236EC2020.pdf</ref>.

**Basic Education is Economically Good:** Literacy and numeracy have substantial economic value. More years in education alone does not improve this economic value, but it must be combined with a rigorous evaluation and curriculum<ref>https://wol.iza.org/articles/what-is-economic-value-of-literacy-and-numeracy</ref>.

RDD shows that university admission yields earnings gains of 22% between 8 and 14 years after HS completion, which outstrip the costs of college attendance<ref>https://econpapers.repec.org/article/ucpjlabec/doi_3a10.1086_2f676661.htm#:~:text=the%20returns%20to%20college%20admission,lunch%20recipients</ref>.

Educational returns for tertiary education have declined over time, although the gap between the educated and less educated has remained similar in most countries. This means that for younger cohorts, tertiary education has become more necessary to survive in the labor market, but the actual economic returns have decreased making tertiary education less sufficient than before<ref>https://link.springer.com/article/10.1007/s10734-018-0353-z#:~:text=we%20analyze%20trends%20over%20three,education%20less%20sufficient%20than%20before</ref>.

From 1997 to 2019, the graduate premium has declined by as much as 20% in some regions, with a country-wide decrease of 10%. On top of a declining premium, graduates are increasingly underemployed. One third of non-recent graduates (those who graduated more than five years ago) are employed in non-graduate roles. This trend is set to worsen, with graduates born in the last two decades considerably more likely to be overeducated relative to their employment<ref>https://www.if.org.uk/2024/01/17/the-state-of-the-graduate-premium/#:~:text=Over%20time%20a%20worrying%20downward,for%20the%201990%20cohort</ref>.

About 40 percent of recent college graduates are “underemployed,” often for a long time. In the mid-1970s, far less than 1 percent of taxi drivers were college graduates; by 2010 more than 15 percent were<ref>https://opportunityamericaonline.org/wp-content/uploads/2017/06/THE-DIMINISHING-RETURNS-OF-A-COLLEGE-DEGREE.pdf#:~:text=not%20be%20better%20for%20more,jobs%20that%20pay%20much%20better</ref>.

Over the period 1995-1998 Italy experienced an expansion of its higher education supply with the aim of reducing regional differences in educational attainment. Findings suggest that enrollment rose as well as the probability of being retained in the university system. The decline in passed exams, especially experienced in Southern regions, casts doubt on the policy effectiveness in reducing regional disparities<ref>https://eric.ed.gov/?id=EJ936139#:~:text=This%20paper%20evaluates%20the%20effects,7%20tables%20and%202%20figures</ref>.

### <span style="background-color:orange">Effects of Schooling</span>

- **Crime: Reduced -** Improved schooling reduces crime rates. The causal link does not appear to be the reverse, as this was researched using randomized treatment, thus in effect acting as an experiment<ref>https://dash.harvard.edu/bitstream/handle/1/12308135/Deming_BSLC_QJE.pdf?sequence=1</ref>.
- **Class Size: Positive -** Class size increases educational attainment even controlling for IQ<ref>https://sci-hub.ru/https://doi.org/10.2307/1164099</ref>.

### <span style="background-color:lightcoral">Types of Schooling</span>

#### <span style="background-color:orange">Homeschooling</span>

**Homeschooling Based** There are a variety of reasons why parents and youth may decide to do homeschooling, including increasing family bonding, to accomplish more academically, to customize or individualize the curriculum and learning environment, to provide a safer environment, or to teach and impart a particular set of values, beliefs, or worldview.The home-educated tend to score above average on achievement tests regardless of their parents' level of formal education and also score above average on SAT and ACT tests. The home-educated typically do above average on measures of social, emotional, and psychological development and tend to engage more in civic life in adulthood. The causality of these relationships is not clear however<ref>https://files.eric.ed.gov/fulltext/ED556234.pdf</ref>.

#### <span style="background-color:orange">Charter Schools</span>

**Mixed:** Charter schools have very heterogeneous effects depending on the study, although on the net there is a small positive effect of charter schools on elementary reading and math, as well as middle school math. There is no statistically significant effect on middle school reading or high school reading or math<ref>https://files.eric.ed.gov/fulltext/ED526353.pdf</ref>. Charter schools tend to be more fiscally costly for school districts because separate governance arrangements can create excess costs and the financing policies can distribute resources to or away from districts<ref>http://www.columbia.edu/~rr2165/pdfs/nycharterfiscal.pdf</ref>.

### <span style="background-color:orange">Performance-Related Pay</span>

**Based:** Performance-related pay positively affects student test scores, especially those which were group-based as opposed to individual-based<ref>https://fordhaminstitute.org/national/commentary/does-teacher-merit-pay-affect-student-test-scores</ref>.

### <span style="background-color:orange">School Choice</span>

**Based:** School choice improves academic outcomes for both choice participants and public schools, saves tax dollars, and reduces racial segregation<ref>https://www.edchoice.org/research-library/?report=win-win-solution/</ref>.

### <span style="background-color:orange">Head Start Program</span>

Compared to at-home care, attending a head start center generates significant positive effects on children's development, although the small average effects exist when comparing Head Start to similar programs<ref>https://www.irle.berkeley.edu/files/2016/IRLE-Revisiting-the-impact-of-Head-Start.pdf</ref>. Moreover, head start has a positive effect on years of education, and beneficial impacts on wage income located at the lower end of the distribution<ref>https://www.econstor.eu/bitstream/10419/142354/1/dp9915.pdf</ref>.

### <span style="background-color:orange">Partisan Bias</span>

There is little evidence of partisan bias in political science grading<ref>https://journals.sagepub.com/doi/abs/10.1177/1532673X14561655?journalCode=aprb</ref>.

### <span style="background-color:orange">Knowledge Retention</span>

Across a variety of fields, students lose a large percentage of the knowledge they receive in a course within the first two years following completion<ref>https://sci-hub.ru/https://doi.org/10.2307/1182376</ref><ref>https://sci-hub.ru/https://doi.org/10.1177/0273475306291463</ref><ref>https://sci-hub.ru/https://doi.org/10.1186/1472-6920-6-5</ref><ref>https://sci-hub.ru/https://doi.org/10.1007/s10459-008-9101-y</ref>.

### <span style="background-color:orange">Tuition</span>

**Spending can be good for student outcomes:** One study finds that per dollar, price cuts are less effective per-dollar than spending increases in terms of increasing postsecondary attainment. Spending has large impacts on enrollment and degree completion<ref>https://scholar.harvard.edu/files/ddeming/files/DW_Aug2017.pdf</ref>. However, a meta-analysis suggests that the mean tuition-enrollment elasticity across studies is close to zero after controlling for publication bias<ref>http://meta-analysis.cz/education/education.pdf</ref>.

**Tuition Control is Possible but Hard** Controlling tuition is often difficult due to substitutions between tuition and fees<ref>https://www.mhec.org/sites/default/files/resources/mhec_affordability_series3_20170824.pdf</ref>. There are only two state policies that are effective in limiting tuition increases. The first is linking tuition to financial aid (high tuition, high financial aid; low tuition, low financial aid), and the second is providing incentives to limit the tuition increase. Tuition was more likely to increase when individual institutions have tuition-setting authority. The average institutional tuition increase in states having tuition caps was higher than increases at institutions in states without tuition caps. This could be because once public universities hear of a cap possibility to be mandated by state authorities, they might preemptively raise tuition and fees. Moreover, since state governments usually don't have enough information about the relationship between the various costs and the quality of learning, it can be hard for states to monitor the rising tuition and fees. Once states set higher tuition caps, institutions may increase tuition up to the limit<ref>https://www.researchgate.net/publication/274489492_The_Impacts_of_State_Control_Policies_on_College_Tuition_Increase</ref>.

**Degree inflation is a concern** Degree inflation is becoming widespread in the US and is making its economy more inefficient. Posting for many jobs traditionally viewed as middle-skills jobs which required a high school diploma only now require at least a college degree. Part of this is due to the changing nature of many middle-skills jobs which require computer proficiency and good written and verbal communications, but it also has to do with misperceptions<ref>https://www.hbs.edu/managing-the-future-of-work/Documents/dismissed-by-degrees.pdf</ref>.

**Aid Increases Tuition** Financial aid and education subsidies increase student demand, and thus increase prices<ref>https://www.cato.org/sites/cato.org/files/pubs/pdf/pa531.pdf</ref><ref>https://www.jamesgmartin.center/wp-content/uploads/2017/12/Bennett_Hypothesis_Paper_Final-1.pdf</ref><ref>https://www.cato.org/blog/cancelling-student-debt-would-inflate-college-prices-suddenly-people-dont-it</ref>.

**Higher tuition colleges tend to be better** Attending a relatively high tuition college has a net positive influence on educational attainment, occupational status, and income. This remained significant even after controlling for student background characteristics such as socioeconomic origins, secondary school achievement, and educational and occupational aspirations. It still remained significant after controlling for academic selectivity and private/public control<ref>https://www.researchgate.net/profile/Mark-Smylie/publication/226126111_College_Tuition_Costs_and_Early_Career_Socioeconomic_Achievement_Do_You_Get_What_You_Pay_For/links/55b21bd608aed621ddfd840d/College-Tuition-Costs-and-Early-Career-Socioeconomic-Achievement-Do-You-Get-What-You-Pay-For.pdf</ref>.

### Misc

A study injected 100% AI written submissions into the examinations system in five undergraduate modules for a BsC degree in Psychology at a reputable UK university for all years. 94% of AI submissions were undetected, and the grades awarded to AI submissions were on average half a grade boundary higher than that achieved by real students. Across modules, there was an 83.4% chance that an AI paper would outperform a real student submission<ref>https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0305354</ref>.

## <span style="background-color:lightcoral">Bad Academia</span>

### Peer Review and Publication Bias

**Pernicious practices are common** Polling of university professors finds that there are many pernicious publication practices, including false criticisms and inferior expertise from peer reviewers<ref>Sci-Hub | Pernicious publication practices. Bulletin of the Psychonomic Society, 18(1), 31–34 | 10.3758/bf03333562. (n.d.). https://sci-hub.ru/https://doi.org/10.3758/BF03333562</ref>.

**Competition increases bias** Across all disciplines, papers are more likely to support a tested hypothesis if their corresponding authors work in states that produce more academic papers per capita. This suggests that competitive academic environments may increase scientists' bias<ref>Fanelli, D. (2010). Do Pressures to Publish Increase Scientists’ Bias? An Empirical Support from US States Data. PLoS ONE, 5(4), e10271. https://doi.org/10.1371/journal.pone.0010271</ref>.

Meta-analyses after controlling for observable biases generally show that the empirical economic effects that are considered “conventional wisdom” are typically much closer to zero and sometimes switch signs. Typically, the relative reduction in effect sizes is 45-60%<ref>https://onlinelibrary.wiley.com/doi/full/10.1111/joes.12630</ref>.

### <span style="background-color:orange">Experts</span>

**Publish or perish culture is cringe** In many cases there exists a necessity to publish for the purposes of career advancement. This leads to poor research design and data analysis<ref>https://royalsocietypublishing.org/doi/pdf/10.1098/rsos.160384</ref>. Competition amongst scientists leads to strategic game-playing in science, a decline in free and open sharing of information and methods, sabotage of others' ability to use one's work, interference with peer-review processes, deformation of relationships, and careless or questionable research conduct.
Competition among scientists for funding, positions and prestige, among other things, is often seen as a salutary driving force in U.S. science. Its effects on scientists, their work and their relationships are seldom considered. Focus-group discussions with 51 mid- and early-career scientists, on which this study is based, reveal a dark side of competition in science. According to these scientists, competition contributes to strategic game-playing in science, a decline in free and open sharing of information and methods, sabotage of others' ability to use one's work, interference with peer-review processes, deformation of relationships, and careless or questionable research conduct. When competition is pervasive, such effects may jeopardize the progress, efficiency and integrity of science<ref>https://sci-hub.ru/https://doi.org/10.1007/s11948-007-9042-5</ref>.

**Researchers can come to very different conclusions using the same data** Breznau et al. (2022) coordinated 161 researchers in 73 research teams to examine their research decisions as they used the same data to independently test the hypothesis that greater immigration reduces public support for social policies. Research teams reported both widely different numerical findings and substantive conclusions despite identical start conditions. Researchers' expertise, prior beliefs, and expectations barely predicted the variation. In fact, more than 95% of the variance remained unexplained. This suggests that many scientific hypotheses remain uncontested for valid reasons<ref>https://www.pnas.org/doi/10.1073/pnas.2203150119</ref>.

**Abstracts are unreliable** Data in abstracts that are inconsistent with or absent from the body of an article is a common occurrence, even within large-circulation general medical journals<ref>https://sci-hub.ru/https://doi.org/10.1001/jama.281.12.1110</ref>.

**Prestiege is predicted by complexity of language in paper** There exists a positive correlation between the prestige of a management research article and its reading difficulty. Passages that are more difficult to read but with identical content are rated as higher in research competence. This suggests that management scientists gain prestige through unintelligible writing<ref>https://sci-hub.se/https://doi.org/10.1287/inte.10.2.80</ref>.

### <span style="background-color:orange">Misconduct, Mistakes, and Retractions in Academia</span>

**Issues in general are common** Misconduct, mistakes, and retractions are common within academia, although getting precise estimates for its prevalence is difficult<ref>https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0005738</ref><ref>https://sci-hub.hkvisa.net/10.1098/rspa.2020.0538</ref>. Misconduct appears to be rising significantly, although it is not clear whether this is due to improved screening practices or changes in the number of publications which have research containing misconduct<ref>https://sci-hub.ru/https://doi.org/10.1073/pnas.1212247109</ref><ref>https://sci-hub.ru/https://doi.org/10.1136/jme.2010.040923</ref>. Higher journal impact factor is positively associated with misconduct as well, although again it is not clear whether this is a screening issue or a publication quality issue<ref>https://sci-hub.ru/https://doi.org/10.1128/IAI.05661-11</ref>. Much of this fraud appears to be deliberately done<ref>https://sci-hub.ru/https://doi.org/10.1136/jme.2010.038125</ref>. Luckily, retractions which occur as a consequence of misconduct result in the author of the publication getting fewer citations in the future, suggesting there is a degree of self-correction which occurs in academia dealing with this<ref>https://www.nature.com/articles/srep03146</ref>. There are a variety of reasons why misconduct occurs<ref>https://sci-hub.ru/https://doi.org/10.1007/s11948-007-9045-2</ref>. Eichorn & Yankauer (1987) looked at a random sample of 50 references in three public health journals. They found that 31% of the total 150 references had citation errors<ref>https://sci-hub.ru/https://doi.org/10.2105/AJPH.77.8.1011</ref>. Much of this research suggests that academia can be fallible in this domain.

### <span style="background-color:orange">Racial Bias in Academia</span>

Even after controlling for scholarly discipline and years as an academic, Black and Hispanic scholars are much less productive than White and Asian scholars, in terms of publication citation counts. Furthermore, Black and Hispanic candidates for full professor are significantly more likely to get promoted for their level of publications and grants than White or Asian candidates<ref>https://erickaufmann.substack.com/p/junk-science-is-being-used-to-prop</ref>.

### <span style="background-color:orange">Political Leanings of Academics</span>

**Left-wing bias in academia exists and is in part due to discrimination/prejudice** Academics lean overwhelmingly left today<ref>https://econjwatch.org/articles/faculty-voter-registration-in-economics-history-journalism-communications-law-and-psychology</ref><ref>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.120.9897&rep=rep1&type=pdf</ref>, although in the past it has been more balanced. This is partially due to differences in intelligence and openness to experience, although this cannot explain all of it. Part of it is also due to self-selection, a hostile climate for right-wingers, and discrimination of right-wingers<ref>https://www.adamsmith.org/research/lackademia-why-do-academics-lean-left</ref><ref>https://psyarxiv.com/qpn57/</ref>. Viewpoint diversity promotes creativity, discovery, and problem-solving, while viewpoint homogeneity promotes confirmation bias and conformity, so having more of a balance of viewpoints will help progress social science<ref>https://sci-hub.hkvisa.net/10.1017/s0140525x15000035</ref>. However, it does not appear that this will affect the political orientation of students, who's political ideology doesn't change with faculty ideology and instead reflects trends of the broader population in their age group<ref>https://www.cambridge.org/core/journals/ps-political-science-and-politics/article/abs/indoctrination-u-faculty-ideology-and-changes-in-student-political-orientation/25ABD9B1A3577F27B5659941CD52D6C9</ref>.

About 9 in 10 American colleges currently suppress freedom of speech, and more than a quarter reach FIRE’s worst speech rating for maintaining codes that both “clearly and substantially” restrict freedom of speech<ref>https://www.thefire.org/news/report-9-10-american-colleges-restrict-free-speech</ref>.

Quasi-experimental evidence using data on 310,000 students who entered 477 American colleges from 1990-2015 suggests that choosing a business major instead of humanities or social sciences reduces liberal self-placement by 0.22 standard deviations or 10 percentage points. Furthermore, the study found that accounting for self-selection into majors, fields of study contribute to political polarization and the observed gender gap in political attitudes among college graduates<ref>https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5196889</ref>.

40 percent of journal editors for the Harvard Law Review have cited protected characteristics when lobbying for or against articles, and the law review eliminates more than 85 percent of submissions using a rubric that asks about “author diversity”<ref>https://freebeacon.com/campus/exclusive-harvard-law-review-axes-85-percent-of-submissions-using-race-conscious-rubric-documents-show/</ref>.

Professors more confident in the truth of taboo conclusions reported more self-censorship, a pattern which could bias perceived scientific consensus regarding the inaccuracy of controversial conclusions. These taboo conclusions ranged from the level of racial discrimination in academia to whether transgender identity is ever a function of social influence. Tenured professors reported as much self-censorship and as much fear of consequences as untenured professors, including fear of getting fired. Younger, more left-leaning and female faculty were generally more opposed to controversial scholarship<ref>https://journals.sagepub.com/doi/10.1177/17456916241252085</ref>.

Gen Z university students tend to emphasize emotional-well being and de-emphasize academic rigor. Men tended to score higher on measures of supporting academic freedom and advancing knowledge, while lower on advancing social justice and emotional well-being compared to females. Emotional stability positively predicted advancing knowledge, while negatively predicting emphasizing emotional well-being. Agreeableness positively predicted emphasizing emotional well-being while negatively predicting advancing knowledge<ref>https://researchers.one/articles/23.03.00001v1</ref>.


DEI statements which exist in many universities are used as one factor to choose whether a prospective faculty candidate should be hired. Research shows that faculty prefer DEI statements that discuss specific types of DEI actions and efforts. Faculty expressed a preference for DEI statements that included a discussion of race/ethnicity and gender DEI actions and efforts and rated lower those statements that neglected to include such content<ref>https://manhattan.institute/article/an-ideological-screening-tool-dei-statements-do-matter-for-faculty-hiring-evaluations?utm_source=LinkedIn&utm_medium=Organic_Social</ref>.

### <span style="background-color:orange">Replicability in Science</span>

**Replicability crisis is real and bad** There exists a replicability crisis in science, particularly in the social sciences<ref>https://www.science.org/doi/10.1126/science.aac4716</ref><ref>https://www.science.org/doi/10.1126/science.aaf0918</ref><ref>https://www.researchgate.net/publication/325216701_Estimating_the_Reproducibility_of_Experimental_Philosophy</ref><ref>https://sci-hub.se/https://doi.org/10.1038/s41562-018-0399-z</ref>. Still, replicability varies between subsets of the social sciences. The degree to which a publication or finding is replicable can in fact be predicted well by scientists<ref>https://sci-hub.se/https://doi.org/10.1038/s41562-018-0399-z</ref>, but are published by journals because they are more interesting. Journal prestige in fact is negatively correlated to replicability<ref>https://sci-hub.ru/https://doi.org/10.3389/fnhum.2018.00037</ref>. This appears to be due to intense competition and time pressure. Nonreplicable publications are cited more than replicable ones<ref>https://sci-hub.ru/https://doi.org/10.1126/sciadv.abd1705</ref>.

### <span style="background-color:orange">Censorship in Academia</span>

**Right-wing stuff is censored** There is a very strong anti right-wing bias in academia in terms of the endorsement of censoring right-wing beliefs. This appears to exist amongst both students and faculty<ref>https://cspicenter.org/wp-content/uploads/2021/03/AcademicFreedom.pdf</ref><ref>https://heterodoxacademy.org/blog/what-the-data-say-about-student-support-for-shout-downs-blockades-and-violence/</ref><ref>https://www.thefire.org/research-learn/academic-mind-2022-what-faculty-think-about-free-expression-and-academic-freedom</ref>. Taking offense is a common experience on campuses and a sizable number of students are in favor of restricting speech on campuses. There is evidence of conformity pressures existing on university campuses. Left-leaning students are less likely to tolerate controversial viewpoints and right-leaning students are more likely to self-censor on politically sensitive issues such as gender, immigration, or sexual and ethnic minorities<ref>https://link.springer.com/article/10.1007/s11577-020-00713-z</ref>.

Among university students in American universities, there is a consistent asymmetry in the percent who are willing to censor conservative versus liberal speakers. The vast majority are more willing to censor conservative versus liberal speakers, with the only two exceptions being Hillsdale College and Liberty University<ref>https://heterodoxacademy.org/blog/is-dei-causing-the-crisis-of-free-speech-on-campus/</ref>:

<img src="https://content.heterodoxacademy.org/cdn-cgi/image/w=1200,h=1182,q=60,f=auto,dpr=2.5,g=0.5x0.5,fit=cover/uploads/Picture2_2023-11-30-014528_wshc.png" alt="Censorship" width="500">

Only 8% of students at Top 20 American universities and 14% of lower-ranked universities are more tolerant of conservative speakers than liberal speakers<ref>https://themissingdatadepot.substack.com/p/ideology-and-intolerance-at-americas</ref>. Interestingly, students are much more intolerant of speakers than faculty are.

The size of a DEI bureaucracy in a university is not related to students' level of tolerance for a liberal speaker, but it is negatively related to tolerance for a conservative speaker. Furthermore, larger DEI bureaucracies are associated with higher levels of support for shouting down a speaker to prevent them from speaking, blocking other students from attending a campus speech, and using violence to stop a campus speech. This suggests that DEI bureaucracies may contribute to a culture of censorship<ref>https://heterodoxacademy.org/blog/is-dei-causing-the-crisis-of-free-speech-on-campus/</ref>. Larger DEI bureaucracies are also associated with lower student comfort with expression outside of classrooms and a greater perceived difficulty to have open and honest conversations<ref>https://themissingdatadepot.substack.com/p/is-dei-destroying-free-speech-on</ref>.

## <span style="background-color:orange">Scientific Distrust</span>

Distrust in science has grown significantly since the onset of COVID<ref>https://www.kumc.edu/communications/about/publications/kansas-medicine-and-science/spring-summer-2023/why-do-so-many-americans-distrust-science.html#:~:text=THE%20CAUSES%20OF%20SCIENCE%20DISTRUST&text=It%20can%20be%20particularly%20challenging,understand%20why%2C%E2%80%9D%20Smith%20said</ref>. There are numerous factors behind this<ref>https://www.aamc.org/news/why-do-so-many-americans-distrust-science</ref>:
*People are overwhelmed by information, and cannot sort out what is true from false
*Trust in institutions is eroding
*Americans are becoming more socially divided and polarized
*Faux experts instill doubt in people
*Contradicting findings undermine trust
*Some groups profit from disinformation

## <span style="background-color:orange">Wokeness</span>

Zagrebbi on wokeness<ref>https://graymirror.substack.com/p/the-origin-of-woke-a-george-mason</ref>:

* Cofnas’s model of wokeness conflicts with one of the stylized facts in traditional sociology: that people generally form their beliefs not from an analytical weighing of relevant issues but based on what will help them as social creatures. This was shown in the 2017 book “The Elephant in the Brain”. The authors argue that while many beliefs are adaptive because they help us model the world accurately, many others are valuable through convincing others that you believe them. 

* This is especially true in the case of ideology. In a market setting, if someone holds implausible beliefs and acts economically based on those beliefs, they tend to lose their money. But in the case of politics, for a political actor the cost of acting on beliefs that incorrectly model the world is very low. But your choice of what political team to support still has an impact, as people socially reward or punish others for their beliefs. So one function of the mind may be to choose beliefs that bring the holder the greatest number of supporters as opposed to those that are most likely to be true. One of the best ways to convince others of one’s belief is to actually believe it, which can result in people believing false or ill-considered things but still have it be in their best interest to do so.

* Wokeness and the equality thesis signals high status and also signals that on average you’re going to behave better towards others. This takes the form of signalling both general niceness as well as how effectively you can avoid offending minorities. Things like land acknowledgements signal that one takes care to promote the interests of those different from oneself, because they are nice. The worse a group behaves, the more the left likes it as being nice to the group is an even stronger signal of one’s closely-held morality. On a micro level, this works for individuals who wish to promote themselves. But on a macro level, it reduces efficiency and is not prosocial.

* Wokeness is a great signal for high status. Elites can continuously distinguish themselves from non-elites through having wokeness continuously evolve to alienate them, making the signal preserve its status even when non-elites may want to be high-status. It also demands things like denigrating your ingroup and praising outgroups which go against natural human impulses, which elites are more willing to accept and swallow aversions to because they are smart and sophisticated enough to intuit that wokeness is high status. Non-elites aren’t as ambitious and so consequently care less about seeming high status in the first place. Woke pushes for homosexuality and transgenderism also have similar dynamics occurring.

* Most anti-wokes are stupid, as Cofnas has shown that whites who attribute lower black SES to genes have verbal IQs of 8.5 points lower than whites who espouse environmentalism. While there are smart race realists, their attachment to this belief signals anti-social things. They are either terrible at self-deception or don’t care enough about signalling identification with the high status ingroup. Noticing that a group is dumb is a powerful signal that you dislike them and mistreat them, while assuming all groups have equal intellectual potential is a powerful signal that you like them and will treat them well. Race realists will naturally tend to be maladjusted, hateful and crazy because of this signal.

* The signalling view can help explain why woke beliefs and leftist beliefs existed before 1960. They were originally meant to signal class-based tolerance when marxism was in fashion and the US was mostly white. But as racial minorities became more common, signalling tolerance for minorities became more important and class-based tolerance became less relevant. 

* Literature as a medium is important in world history because it is so good at coordinating ideological movements. Books today can be used to have a public relations campaign, to power a media blitz about your ideas. Rufo misses that Marxists are familiar with Marx, but basically no woke person has heard of Marcuse, Adorno or even Angela Davis. That’s because class-based ideas became irrelevant. This relative ideological incoherence hinders the possibility of a woke version of the USSR, as there is no clear vision unlike with marxism. Ditching marxism’s literature tactic may have led to woke’s confusion, but it allows it to become a mass ideology which doesn’t require one to read tons of theory.

* Ultimately doing more race and iq research will not win people because it assumes that people believe things because they are true, when in reality they believe things because they signal high status. This signalling view also suggests that wokeness is very sticky and will naturally be ubiquitous. Hanania, pointing to civil rights law for why society became woke, cannot explain why the judges who did caselaw for the new legislation were woke.

<img src="https://substackcdn.com/image/fetch/$s_!ZjEl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d72a0e9-4091-410c-a817-f765b5844c00_1282x1232.png" alt="Four Models of Wokeness" width="500">

## References

<references />
